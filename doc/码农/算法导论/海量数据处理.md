分而治之/hash映射 + hash统计 + 堆/快速/归并排序；
双层桶划分
Bloom filter/Bitmap；
Trie树/数据库/倒排索引；
外排序；
分布式处理之Hadoop/Mapreduce

https://www.csdn.net/gather_27/MtTaYg5sOTQ3MS1ibG9n.html
https://www.jianshu.com/p/f56ef7b23686
1.对于亿万级别的数据(同型且有重复)  统计其中出现次数最多的前N个数据
顺序读文件中，对于每个词x，取hash(x)%5000，然后按照该值存到5000个小文件（记为x0,x1,…x4999）中。这样每个文件大概是200k左右。
如果其中的有的文件超过了1M大小，还可以按照类似的方法继续往下分，直到分解得到的小文件的大小都不超过1M。
对每个小文件，统计每个文件中出现的词以及相应的频率（可以采用trie树/hash_map等），并取出出现频率最大的100个词（可以用含100个结 点的最小堆），并把100个词及相应的频率存入文件，这样又得到了5000个文件。下一步就是把这5000个文件进行归并（类似与归并排序）的过程了。



2.从一亿个整数里面找出100个最大的数？
https://blog.csdn.net/qq_39521554/article/details/79546854

200个G带有IP地址访问记录的log日志，从中分析访问次数最多的IP地址。（面试官提示：分治递归的策略）

